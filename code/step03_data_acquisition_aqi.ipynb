{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project: Wildfire Analysis (Part 1: Common Analysis)\n",
    "\n",
    "## Request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API.\n",
    "\n",
    "More and more frequently summers in the western US have been characterized by wildfires with smoke billowing across multiple western states. There are many proposed causes for this: climate change, US Forestry policy, growing awareness, just to name a few. Regardless of the cause, the impact of wildland fires is widespread as wildfire smoke reduces the air quality of many cities. There is a growing body of work pointing to the negative impacts of smoke on health, tourism, property, and other aspects of society.\n",
    "\n",
    "The Course Project is designed to analyze the impacts of wildfires on specific cities in the United States, particularly focusing on the effects of wildfire smoke and its implications for public health, air quality, and overall community well-being.\n",
    "\n",
    "This is the first step in the project, where all the students conduct a base analysis using a shared dataset while focusing on a unique city. The aim is to create an understanding of wildfire impacts tailored to local contexts.\n",
    "\n",
    "In this notebook, we will request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API.\n",
    "\n",
    "This is a historical API and does not provide real-time air quality data. The [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) for the API provides definitions of the different call parameter and examples of the various calls that can be made to the API.\n",
    "\n",
    "This notebook works systematically, requesting an API key, using 'list' to get various IDs and parameter values, and using 'daily summary' to get summary data that meets specific condistions. Changing values to explore the results of the API is probably useful, but that will result in some explanations being out of sync with the outputs.\n",
    "\n",
    "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. \n",
    "\n",
    "The end goal of this notebook is to get to some values that we might use for the Air Quality Index or AQI. The AQI index is meant to tell us something about how healthy or clean the air is on any day. The AQI is actually a somewhat complext measure. \n",
    "\n",
    "Other references:  [how to calculate the AQI](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf).\n",
    "\n",
    "**License**:\n",
    "Many of the snippets used here was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 16, 2024\n",
    "\n",
    "\n",
    "\n",
    "## 1. Import libraries and required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are standard python modules\n",
    "import os, json, time\n",
    "\n",
    "# The 'requests' module is a distribution module for making web requests. If you do not have it already, you'll need to install it\n",
    "import requests\n",
    "\n",
    "# suppress the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import pandas for the data processing step\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    CONSTANTS\n",
    "#    This is the root of all AQS API URLs\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#    These are some of the 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "\n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n",
    "# A dictionary of the city location from the US west coast state.\n",
    "CITY_LOCATIONS = {\n",
    "    'vancouver' :   {'city'   : 'Vancouver',\n",
    "                    'county' : 'Clark',\n",
    "                    'state'  : 'Washington',\n",
    "                    'fips'   : '53011',\n",
    "                    'latlon' : [45.64, -122.60] }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been assigned to analyse the city: Vancouver, WA for my analysis\n",
    "- 2023 estimate: 196442\n",
    "- 2020 census: 190915\n",
    "- 2020 density: 3920\n",
    "- Latitude/Longitude: 45.64°N 122.60°W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making a sign-up request\n",
    "\n",
    "Before using the API, we need to request a key. We will use an email address to make the request. The EPA then sends a confirmation email link and a 'key' that we need to use for all other requests.\n",
    "\n",
    "You only need to sign-up once, unless you want to invalidate your current key (by getting a new key) or you lose your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
    "#    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
    "#    email address.\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL, \n",
    "                   endpoint_action = API_ACTION_SIGNUP, \n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "    \n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address        \n",
    "    \n",
    "    if not request_template['email']: \n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "\n",
    "    if '@' not in request_template['email']: \n",
    "        raise Exception(f\"Must supply an email address to call 'request_signup()'. The string '{request_template['email']}' does not look like an email address.\")\n",
    "\n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SIGNUP request is only to be done once, to request a key. A key is sent to that email address and needs to be confirmed with a click through. This code should probably be commented out after you've made your key request to make sure you don't accidentally make a new sign-up request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting SIGNUP ...\n",
      "{\n",
      "    \"Header\": [\n",
      "        {\n",
      "            \"status\": \"Success\",\n",
      "            \"request_time\": \"2024-10-30T15:49:37-04:00\",\n",
      "            \"url\": \"https://aqs.epa.gov/data/api/signup?email=pj2901@uw.edu\"\n",
      "        }\n",
      "    ],\n",
      "    \"Data\": [\n",
      "        \"You should receive a registration confirmation email with a link for confirming your email shortly.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print(\"Requesting SIGNUP ...\")\n",
    "# USERNAME = \"pj2901@uw.edu\"\n",
    "# response = request_signup(USERNAME)\n",
    "# print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign your email address to \"USERNAME\" and your key to \"APIKEY\" as constants and the remaining cells in the notbook should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have the signup email, we can define two constants:\n",
    "#   USERNAME - This should be the email address you sent the EPA asking for access to the API during sign-up\n",
    "#   APIKEY   - This should be the authorization key they sent you\n",
    "\n",
    "# Specify the values as constants below. Just don't distribute the notebook without removing the\n",
    "# constants or you'll be distributing your key too.\n",
    "\n",
    "# USERNAME = \"pj2901@uw.edu\"\n",
    "# APIKEY = <key>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making a list request\n",
    "\n",
    "Once we have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. The one problem here is that some of the responses rely on jargon or terms-of-art. That is, one needs to know a bit about the way atmospheric sciece works to understand some of the terms. ... Good thing we can use the web to search for terms we don't know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors \n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL, \n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES, \n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "    \n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    \n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"AIRNOW MAPS\",\n",
      "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"ALL\",\n",
      "        \"value_represented\": \"Select all Parameters Available\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"AQI POLLUTANTS\",\n",
      "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CORE_HAPS\",\n",
      "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CRITERIA\",\n",
      "        \"value_represented\": \"Criteria Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CSN DART\",\n",
      "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"FORECAST\",\n",
      "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"HAPS\",\n",
      "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE CARBON\",\n",
      "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE_SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"MET\",\n",
      "        \"value_represented\": \"Meteorological Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS CORE HAPS\",\n",
      "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS REQUIRED\",\n",
      "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS\",\n",
      "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS_VOC\",\n",
      "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM COARSE\",\n",
      "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM10 SPECIATION\",\n",
      "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 CONT NONREF\",\n",
      "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 MASS/QA\",\n",
      "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SCHOOL AIR TOXICS\",\n",
      "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CARBON\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CATION/ANION\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION METALS\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP CARBONYL\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP VOC\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"VOC\",\n",
      "        \"value_represented\": \"Volatile organic compounds\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in getting to something that might be the Air Quality Index (AQI). You see this reported on the news - often around smog values, but also when there is smoke in the sky. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash ...).\n",
    "\n",
    "From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"42101\",\n",
      "        \"value_represented\": \"Carbon monoxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42401\",\n",
      "        \"value_represented\": \"Sulfur dioxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42602\",\n",
      "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"44201\",\n",
      "        \"value_represented\": \"Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"81102\",\n",
      "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88101\",\n",
      "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88502\",\n",
      "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have (above) a response containing a set of sensor ID numbers. The list should include the sensor numbers as well as a description or name for each sensor. \n",
    "\n",
    "The EPA AQS API has limits on some call parameters. Specifically, when we request data for sensors we can only specify a maximum of 5 different sensor values to return. This means we cannot get all of the Air Quality Index parameters in one request for data. We have to break it up.\n",
    "\n",
    "We broke up the request into two logical groups, the AQI sensors that sample gasses and the AQI sensors that sample particles in the air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Air quality monitoring stations are located all over the US at different locations. \n",
    "\n",
    "This list includes the [FIPS](https://www.census.gov/library/reference/code-lists/ansi.html) number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant.\n",
    "\n",
    "Given our CITY_LOCATIONS constant we can now find which monitoring locations are nearby. One option is to use the county to define the area we're interest in. You can get the EPA to list their monitoring stations by county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0003\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0004\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0005\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0006\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0007\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0008\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0009\",\n",
      "        \"value_represented\": \"19912 NE 164TH ST HOCKINSON SCHOOL IN BRUSH PRAIRIE, WA\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0010\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0011\",\n",
      "        \"value_represented\": \"VANCOUVER - BLAIRMONT DR\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0012\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0013\",\n",
      "        \"value_represented\": \"VANCOUVER - 4TH PL BLVD E\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0014\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0015\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0016\",\n",
      "        \"value_represented\": \"HAZELDELL/7701 NE HIGHWAY 99\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0017\",\n",
      "        \"value_represented\": \"BONNEVILLE POWER ADMINISTRATION ROSS SUBSTATION 54TH ST & HWY 99\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0018\",\n",
      "        \"value_represented\": \"Vancouver-River Rd\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0019\",\n",
      "        \"value_represented\": \"VANCOUVER - MACARTHUR BLVD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0020\",\n",
      "        \"value_represented\": \"CAMAS CITY HALL, 616 NE 4TH AVE, CAMAS, WA\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0021\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0022\",\n",
      "        \"value_represented\": \"YACOLT - YACOLT RD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0023\",\n",
      "        \"value_represented\": \"Vancouver-NE Vancouver Plaza Dr\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0024\",\n",
      "        \"value_represented\": \"Vancouver-NE 84th Ave\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0030\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1003\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2001\",\n",
      "        \"value_represented\": null\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['vancouver']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['vancouver']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above response gives us a list of monitoring stations. Each monitoring station has a unique \"code\" which is a string number, and, sometimes, a description. The description seems to be something about where the monitoring station is located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making a daily summary request\n",
    "\n",
    "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date. \n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of the daily summary response is a bit verbose with lots of repeated values. What we'll do is create a data structure that relies on a hierarchical context to summarize the data.\n",
    "\n",
    "The next function takes the response and a set of fields that should be extracted for their data values. The code assumes those fields are available. If there are missing values something could certainly go wrong. The function creates a summary for each monitoring site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    This is a list of field names - data - that will be extracted from each record\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#    The function creates a summary record\n",
    "def extract_summary_from_response(r=None, fields=EXTRACTION_FIELDS):\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "        \n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "        \n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Get AQI Particulates data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No date for the year:  1961\n",
      "No date for the year:  1962\n",
      "No date for the year:  1963\n",
      "No date for the year:  1964\n",
      "No date for the year:  1965\n",
      "No date for the year:  1966\n",
      "No date for the year:  1967\n",
      "No date for the year:  1968\n",
      "No date for the year:  1969\n",
      "No date for the year:  1970\n",
      "No date for the year:  1971\n",
      "No date for the year:  1972\n",
      "No date for the year:  1973\n",
      "No date for the year:  1974\n",
      "No date for the year:  1975\n",
      "No date for the year:  1976\n",
      "No date for the year:  1977\n",
      "No date for the year:  1978\n",
      "No date for the year:  1979\n",
      "No date for the year:  1980\n",
      "No date for the year:  1981\n",
      "No date for the year:  1982\n",
      "No date for the year:  1983\n",
      "No date for the year:  1984\n",
      "No date for the year:  1985\n",
      "No date for the year:  1986\n",
      "No date for the year:  1987\n",
      "No date for the year:  1988\n",
      "No date for the year:  1989\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "request_data['state'] = CITY_LOCATIONS['vancouver']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['vancouver']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "particulate_data = []\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1961\n",
    "end_year = 2024\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    # print(json.dumps(particulate_aqi['Data'],indent=4))\n",
    "\n",
    "    # check the response\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "        particulate_data.append(extract_particulate)\n",
    "\n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(\"No date for the year: \", year)\n",
    "    \n",
    "    else:\n",
    "        print(\"Error in getting the data for year: \", year)\n",
    "        # print(json.dumps(particulate_aqi,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particulate data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Write the data stored in 'particulate_data' to the specified JSON file\n",
    "output_file_path = \"../intermediate_data/aqi_particulate_data_raw.json\"\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(particulate_data, file, indent=4)\n",
    "\n",
    "print(\"Particulate data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get AQI Gaseous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No date for the year:  1961\n",
      "No date for the year:  1962\n",
      "No date for the year:  1963\n",
      "No date for the year:  1964\n",
      "No date for the year:  1965\n",
      "No date for the year:  1966\n",
      "No date for the year:  1967\n",
      "No date for the year:  1968\n",
      "No date for the year:  1969\n",
      "No date for the year:  1970\n",
      "No date for the year:  1971\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['vancouver']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['vancouver']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "gaseous_data = []\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1961\n",
    "end_year = 2024\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    # print(json.dumps(particulate_aqi['Data'],indent=4))\n",
    "\n",
    "    # check the response\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "        gaseous_data.append(extract_gaseous)\n",
    "\n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(\"No date for the year: \", year)\n",
    "    \n",
    "    else:\n",
    "        print(\"Error in getting the data for year: \", year)\n",
    "        # print(json.dumps(particulate_aqi,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particulate data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Write the data stored in 'gaseous_data' to the specified JSON file\n",
    "output_file_path = \"../data/intermediate_data/aqi_gaseous_data_raw.json\"\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(particulate_data, file, indent=4)\n",
    "\n",
    "print(\"Particulate data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aqi(data_dict, additional_keys=None):\n",
    "    if additional_keys is None:\n",
    "        additional_keys = []\n",
    "\n",
    "    aqi_data_list = []\n",
    "\n",
    "    for item_key, item_value in data_dict.items():\n",
    "        # create the current key path by appending the current key to the list of additional keys\n",
    "        current_key_path = additional_keys + [item_key]\n",
    "\n",
    "        # if the current value is a dictionary, call extract_aqi\n",
    "        if isinstance(item_value, dict):\n",
    "            aqi_data_list.extend(extract_aqi(item_value, current_key_path))\n",
    "        \n",
    "        # else, if the current value is a list, iterate through the list items\n",
    "        elif isinstance(item_value, list):\n",
    "            for sub_item in item_value:\n",
    "                if isinstance(sub_item, dict):  # check if the list item is a dictionary\n",
    "                    aqi_value = sub_item.get(\"aqi\") # extract AQI valuea\n",
    "                    sample_duration_value = sub_item.get(\"sample_duration\") # get the sample duration values\n",
    "\n",
    "                    # If AQI is present, add the data to the list\n",
    "                    if aqi_value is not None:\n",
    "                        aqi_data_list.append({\n",
    "                            \"keys\": current_key_path,\n",
    "                            \"sample_duration\": sample_duration_value,\n",
    "                            \"aqi\": aqi_value\n",
    "                        })\n",
    "\n",
    "    return aqi_data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract and process AQI data from a list of datasets related to particulate matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_particulate_data = []\n",
    "\n",
    "for dataset in particulate_data:\n",
    "    extracted_particulate_data.extend(extract_aqi(dataset))\n",
    "\n",
    "# process the extracted AQI data\n",
    "for entry in extracted_particulate_data:\n",
    "    key_hierarchy = \" > \".join(entry[\"keys\"])\n",
    "    aqi_value = entry[\"aqi\"]\n",
    "    sample_duration_value = entry['sample_duration']\n",
    "    # print(f\"Keys: {key_hierarchy}, AQI: {aqi_value}, Sample Duration: {sample_duration_value}\")\n",
    "\n",
    "# print(extracted_particulate_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract and process AQI data from a list of datasets related to gaseous matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_gaseous_data = []\n",
    "\n",
    "for dataset in gaseous_data:\n",
    "    extracted_gaseous_data.extend(extract_aqi(dataset))\n",
    "\n",
    "# process the extracted AQI data\n",
    "for entry in extracted_gaseous_data:\n",
    "    key_hierarchy = \" > \".join(entry[\"keys\"])\n",
    "    aqi_value = entry[\"aqi\"]\n",
    "    sample_duration_value = entry['sample_duration']\n",
    "    # print(f\"Keys: {key_hierarchy}, AQI: {aqi_value}, Sample Duration: {sample_duration_value}\")\n",
    "\n",
    "# print(extracted_gaseous_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will processes the extracted AQI data to create a dataFrame that organizes information by date, AQI value, sample duration, and pollutant type. I am more used to performing analysis using Pandas, so this helps me do further analysis.\n",
    "\n",
    "First, we will do for the particulate matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-02-04</td>\n",
       "      <td>9</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-10</td>\n",
       "      <td>6</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-02-16</td>\n",
       "      <td>12</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-22</td>\n",
       "      <td>19</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>19</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  AQI sample_duration pollutant_type\n",
       "0 1990-02-04    9         24 HOUR          81102\n",
       "1 1990-02-10    6         24 HOUR          81102\n",
       "2 1990-02-16   12         24 HOUR          81102\n",
       "3 1990-02-22   19         24 HOUR          81102\n",
       "4 1990-02-28   19         24 HOUR          81102"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi_data = []\n",
    "\n",
    "for record in extracted_particulate_data:\n",
    "    key = record['keys']\n",
    "    date = key[-1]\n",
    "\n",
    "    aqi = record['aqi']\n",
    "    duration_of_sample = record['sample_duration']\n",
    "    type_of_pollutant = key[-3]\n",
    "\n",
    "    aqi_data.append({\n",
    "        'date': date,\n",
    "        'AQI': aqi,\n",
    "        'sample_duration': duration_of_sample,\n",
    "        'pollutant_type': type_of_pollutant\n",
    "    })\n",
    "\n",
    "particulate_df = pd.DataFrame(aqi_data)\n",
    "particulate_df['date'] = pd.to_datetime(particulate_df['date'], format='%Y%m%d')\n",
    "particulate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same for gaseous matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>sample_duration</th>\n",
       "      <th>pollutant_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-02-04</td>\n",
       "      <td>29</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-10</td>\n",
       "      <td>29</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-02-16</td>\n",
       "      <td>29</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-22</td>\n",
       "      <td>29</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>14</td>\n",
       "      <td>1 HOUR</td>\n",
       "      <td>42401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  AQI sample_duration pollutant_type\n",
       "0 1990-02-04   29          1 HOUR          42401\n",
       "1 1990-02-10   29          1 HOUR          42401\n",
       "2 1990-02-16   29          1 HOUR          42401\n",
       "3 1990-02-22   29          1 HOUR          42401\n",
       "4 1990-02-28   14          1 HOUR          42401"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi_data = []\n",
    "\n",
    "for record in extracted_gaseous_data:\n",
    "    key = record['keys']\n",
    "    date = key[-1]\n",
    "\n",
    "    aqi = record['aqi']\n",
    "    duration_of_sample = record['sample_duration']\n",
    "    type_of_pollutant = key[-3]\n",
    "\n",
    "    aqi_data.append({\n",
    "        'date': date,\n",
    "        'AQI': aqi,\n",
    "        'sample_duration': duration_of_sample,\n",
    "        'pollutant_type': type_of_pollutant\n",
    "    })\n",
    "\n",
    "gaseous_df = pd.DataFrame(aqi_data)\n",
    "gaseous_df['date'] = pd.to_datetime(particulate_df['date'], format='%Y%m%d')\n",
    "gaseous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned files \n",
    "particulate_df.to_csv(\"../data/intermediate_data/aqi_particulate_data_clean.csv\")\n",
    "gaseous_df.to_csv(\"../data/intermediate_data/aqi_gaseous_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Combine the particulate and gaseous matter data to obtain the AQI dataset\n",
    "\n",
    "I want to combine and analyze air quality data from particulate_df and gaseous_df. Since I want to highlight peak pollution values and understand the highest levels of air quality degradation associated with your smoke estimate in the next step, I will take sum of either of the two values. If suppose particulate data is not available, it will be filled with the dataset mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-02-04</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-02-16</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-22</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   AQI\n",
       "0  1990-02-04   9.0\n",
       "1  1990-02-10   6.0\n",
       "2  1990-02-16  12.0\n",
       "3  1990-02-22  19.0\n",
       "4  1990-02-28  19.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particulate_df = particulate_df.drop(['sample_duration', 'pollutant_type'], axis=1)\n",
    "particulate_df_by_date = particulate_df.groupby('date', as_index=False).mean()\n",
    "particulate_df_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-02-04</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-10</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-02-16</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-22</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   AQI\n",
       "0  1990-02-04  29.0\n",
       "1  1990-02-10  29.0\n",
       "2  1990-02-16  29.0\n",
       "3  1990-02-22  29.0\n",
       "4  1990-02-28  14.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaseous_df = gaseous_df.drop(['sample_duration', 'pollutant_type'], axis=1)\n",
    "gaseous_df_by_date = gaseous_df.groupby('date', as_index=False).mean()\n",
    "gaseous_df_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-02-04</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-10</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-02-16</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-02-22</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   AQI\n",
       "0 1990-02-04  38.0\n",
       "1 1990-02-10  35.0\n",
       "2 1990-02-16  41.0\n",
       "3 1990-02-22  48.0\n",
       "4 1990-02-28  33.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the dataframes on 'date' and obtain the sum of AQI\n",
    "final_aqi_df_by_date = gaseous_df_by_date.merge(particulate_df_by_date, on='date', how='outer', suffixes=('_gaseous', '_particulate'))\n",
    "\n",
    "# calculate the total AQI by summing the two types of AQI\n",
    "final_aqi_df_by_date['AQI'] = final_aqi_df_by_date[['AQI_gaseous', 'AQI_particulate']].sum(axis=1)\n",
    "\n",
    "# replace empty values with the mean of available AQI data\n",
    "mean_aqi = final_aqi_df_by_date['AQI'].mean()\n",
    "final_aqi_df_by_date['AQI'].fillna(mean_aqi, inplace=True)\n",
    "final_aqi_df_by_date.drop(columns=['AQI_gaseous', 'AQI_particulate'], inplace=True)\n",
    "\n",
    "final_aqi_df_by_date['date'] = pd.to_datetime(final_aqi_df_by_date['date'])\n",
    "final_aqi_df_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe for future reference\n",
    "final_aqi_df_by_date.to_csv(\"../data/intermediate_data/aqi_data_grouped_by_date.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be comparing the AQI data with the smoke estimate we created in the previous step. Since we have grouped our smoke estimate data by year, we will do the same for AQI values as well. I am getting the mean AQI values. \n",
    "\n",
    "Further, I am saving the dataset for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>54.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>52.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>56.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>47.426230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>49.564516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        AQI\n",
       "0  1990  54.318966\n",
       "1  1991  52.859375\n",
       "2  1992  56.285714\n",
       "3  1993  47.426230\n",
       "4  1994  49.564516"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_aqi_df_by_date['year'] = final_aqi_df_by_date['date'].dt.year # get the year from date\n",
    "\n",
    "final_aqi_df_by_year = final_aqi_df_by_date.groupby('year')['AQI'].mean().reset_index() # group by 'year' and calculate the mean AQI\n",
    "\n",
    "final_aqi_df_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe for future reference\n",
    "final_aqi_df_by_year.to_csv(\"../data/intermediate_data/aqi_data_grouped_by_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
